---
title: "Predicción del rating de Las aplicaciones en Google Play Store"
subtitle: "Reto DataSource"
author: "[Edimer (Sidereus)](https://edimer.github.io/)"
output:
  html_notebook:
    toc: true
    toc_float: 
      smooth_scroll: false
      collapsed: false
    highlight: pygments
    theme: spacelab
    css: estilo.css
    code_folding: show
---

<center>
<img src = "../img/competencia.png" />
</center>

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center")
```

- [Sitio oficial del reto en DataSource.](https://www.datasource.ai/es/home/data-science-competitions-for-startups/prediciendo-el-rating-de-las-aplicaciones-en-google-play-store)

# Metodología

- Las siguientes imágenes fueron tomadas del libro [Tidy Modeling with R](https://xgboost.readthedocs.io/en/latest/parameter.html) de [Max Kuhn](https://github.com/topepo) y [Julia Silge.](https://github.com/juliasilge)

## Marco General

<center>
<img src = "https://www.tmwr.org/premade/data-science-model.svg" height = 450/>
</center>

## Estrategia de Validación

- La siguiente imagen fue tomada de [tidymodels.org](https://www.tidymodels.org/start/case-study/) e ilustra la estrategia de evaluación de modelos que adopté.

<center>
<img src = "https://www.tidymodels.org/start/case-study/img/validation-split.svg" height = 450/>
</center>

## Fases del Modelado

<center>
<img src = "https://www.tmwr.org/premade/modeling-process.svg" height = 450/>
</center>

## Libros

### *Tidy Modeling with R*

<center>
<img src = "../img/libro.PNG" height = 450/>
</center>

### *Applied Predictive Modeling*

- Consultar el libro [aquí.](http://appliedpredictivemodeling.com/)

<center>
<img src = "http://static1.squarespace.com/static/51156277e4b0b8b2ffe11c00/t/51157487e4b0b8b2ffe16829/1588028705660/?format=1500w" height = 450/>
</center>

### *Feature Engineering and Selection A Practical Approach for Predictive Models*

- Consultar libro [aquí.](http://www.feat.engineering/)

<center>
<img src = "https://images.routledge.com/common/jackets/amazon/978113807/9781138079229.jpg" height = 450/>
</center>

# Variables

<center>
<img src = "../img/variables.PNG" />
</center>

# Ensamble RF, XGBoost, SVM y Catboost

- Random Forest entrenado con R. Este algoritmo presenta buenos resultados para clasificar el "0".
- El modelo XGBoost fue ajustado con R. Arrojó mejores resultados que el ajustado con Python.
- La máquina de soporte vectorial tiende a tener buenos resultados para clasificar el "0".
- Catboost entrenado con Python es el de mejores resultados hasta el momento.

```{r}
library(tidyverse)
subm3 <- read_csv("../submission/sub_03_svmR.csv") %>% 
  rename(svmR = rating)

subm6 <- read_csv("../submission/sub_06_rf.csv") %>% 
  rename(rf = rating)

subm9 <- read_csv("../submission/sub_09_xgboost.csv") %>% 
  rename(xgb3 = rating)

subm17 <- read_csv("../submission/sub_17_catboost_boosting.csv") %>% 
  rename(catboost = rating)

```

- **Data con predicciones de todos los modelos:**

```{r}
subm_completa <- inner_join(subm3, subm6, by = "id") %>% 
  inner_join(subm9, by = "id") %>% 
  inner_join(subm17, by = "id")
head(subm_completa)
```


- **Ensamble:** el resultado de la "bandera" se interpreta de la siguiente manera:
  - Cuando el resultado es "1" todos los modelos clasificaron como "1" esa observación.
  - Cuando el resultado es "0" todos los modelos clasificación como "0" esa observación.
  - Cuando el resultado es "0.75" tres modelos clasificaron como "1" y un solo modelo clasificó lo contrario.
  - Cuando el resultado es "0.25" tres modelos clasificaron como "0" y un solo modelo clasificó lo contrario.
  - Cuando el resultado es "0.5" dos modelos clasificaron como "0" y los otros dos clasificaron como "1". En este caso opto por dejar la predicción del resultado de mayor puntaje en el tablero de la competencia, que en este caso es Catboost Boosting entrenado con Python (pycaret).  

```{r}
subm_completa %>% 
  mutate(bandera = svmR + rf + xgb3 + catboost,
         promedio = bandera / 4,
         promedio = as.character(promedio),
         rating = if_else(promedio == "1", true = 1,
                          false = if_else(
                            promedio == "0", true = 0,
                            false = if_else(
                              promedio == "0.75", true = 1,
                              false = if_else(
                                promedio == "0.25", true = 0,
                                false = xgb3
                              )
                            )
                          ))) %>% 
  select(id, rating) ->
  sub_26_ensamble_svmRRFXGBCatboost
head(sub_26_ensamble_svmRRFXGBCatboost)
```

- **Exportando predicciones:**

```{r}
write_csv(sub_26_ensamble_svmRRFXGBCatboost,
          file = "../submission/sub_26_ensamble_svmRRFXGBCatboostBoosting.csv")
```


# Ensamble XGBoost, RF y Catboost

- El modelo XGBoost fue ajustado con R. Arrojó mejores resultados que el ajustado con Python.
- Random Forest entrenado con R. Este algoritmo presenta buenos resultados para clasificar el "0".
- Catboost entrenado con Python es el de mejores resultados hasta el momento.

```{r}
library(tidyverse)

subm6 <- read_csv("../submission/sub_06_rf.csv") %>% 
  rename(rf = rating)

subm9 <- read_csv("../submission/sub_09_xgboost.csv") %>% 
  rename(xgb3 = rating)

subm17 <- read_csv("../submission/sub_17_catboost_boosting.csv") %>% 
  rename(catboost = rating)

```

- **Data con predicciones de todos los modelos:**

```{r}
subm_completa <- inner_join(subm6, subm9, by = "id") %>% 
  inner_join(subm17, by = "id")
head(subm_completa)
```


- **Ensamble:** el resultado de la "bandera" se interpreta de la siguiente manera:
  - Las sumas que den tres en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "1".
  - Las sumas que den cero en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "0".
  - Las sumas que den dos en la variable "bandera" son coincidencias en dos de los modelos para la etiqueta "1".
  - Obtengo el promedio por fila. Aquellos promedios iguales a 0.6666667 les asigno la etiqueta "1" y aquellos con promedio igual a 0.3333333 les asigno la etiqueta "0". Esto lo hago asumiendo que la mayoría tienen "la razón". Si no está en ninguna de estas opciones mantengo la predicción del modelo catboost, que fue el de mayor puntaje en la competencia. 

```{r}
subm_completa %>% 
  mutate(bandera = rf + xgb3 + catboost,
         promedio = bandera / 3,
         promedio = as.character(promedio),
         rating = if_else(promedio == "0.333333333333333", true = 0,
                          false = if_else(
                            promedio == "0.666666666666667", true = 1,
                            false = catboost
                          ))) %>% 
  select(id, rating) ->
  sub_27_ensamble_svmRXGBCatboost
head(sub_27_ensamble_svmRXGBCatboost)
```

- **Exportando predicciones:**

```{r}
write_csv(sub_27_ensamble_svmRXGBCatboost,
          file = "../submission/sub_27_ensamble_svmRXGBCatboostBoosting.csv")
```


# Ensamble XGBoost, RF y Catboost

- El modelo XGBoost fue ajustado con R. Arrojó mejores resultados que el ajustado con Python.
- Random Forest entrenado con R. Este algoritmo presenta buenos resultados para clasificar el "0".
- Catboost entrenado con Python es el de mejores resultados hasta el momento.

```{r}
library(tidyverse)

subm6 <- read_csv("../submission/sub_06_rf.csv") %>% 
  rename(rf = rating)

subm9 <- read_csv("../submission/sub_09_xgboost.csv") %>% 
  rename(xgb3 = rating)

subm17 <- read_csv("../submission/sub_17_catboost_boosting.csv") %>% 
  rename(catboost = rating)

```

- **Data con predicciones de todos los modelos:**

```{r}
subm_completa <- inner_join(subm6, subm9, by = "id") %>% 
  inner_join(subm17, by = "id")
head(subm_completa)
```


- **Ensamble:** el resultado de la "bandera" se interpreta de la siguiente manera:
  - Las sumas que den tres en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "1".
  - Las sumas que den cero en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "0".
  - Las sumas que den dos en la variable "bandera" son coincidencias en dos de los modelos para la etiqueta "1".
  - Obtengo el promedio por fila. Aquellos promedios iguales a 0.6666667 les asigno la etiqueta "1" y aquellos con promedio igual a 0.3333333 les asigno la etiqueta "0". Esto lo hago asumiendo que la mayoría tienen "la razón". Si no está en ninguna de estas opciones mantengo la predicción del modelo xgboost, que fue el de mayor puntaje en la competencia. 

```{r}
subm_completa %>% 
  mutate(bandera = rf + xgb3 + catboost,
         promedio = bandera / 3,
         promedio = as.character(promedio),
         rating = if_else(promedio == "0.333333333333333", true = 0,
                          false = if_else(
                            promedio == "0.666666666666667", true = 1,
                            false = xgb3
                          ))) %>% 
  select(id, rating) ->
  sub_28_ensamble_svmRXGBCatboost
head(sub_28_ensamble_svmRXGBCatboost)
```

- **Exportando predicciones:**

```{r}
write_csv(sub_28_ensamble_svmRXGBCatboost,
          file = "../submission/sub_28_ensamble_svmRXGBCatboostBoosting.csv")
```

# Ensamble XGBoost, SVM y Catboost

- El modelo XGBoost fue ajustado con R. Arrojó mejores resultados que el ajustado con Python.
- La máquina de soporte vectorial tiende a tener buenos resultados para clasificar el "0".
- Catboost entrenado con Python es el de mejores resultados hasta el momento.

```{r}
library(tidyverse)

subm3 <- read_csv("../submission/sub_03_svmR.csv") %>% 
  rename(svmR = rating)

subm9 <- read_csv("../submission/sub_09_xgboost.csv") %>% 
  rename(xgb3 = rating)

subm17 <- read_csv("../submission/sub_17_catboost_boosting.csv") %>% 
  rename(catboost = rating)

```

- **Data con predicciones de todos los modelos:**

```{r}
subm_completa <- inner_join(subm3, subm9, by = "id") %>% 
  inner_join(subm17, by = "id")
head(subm_completa)
```


- **Ensamble:** el resultado de la "bandera" se interpreta de la siguiente manera:
  - Las sumas que den tres en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "1".
  - Las sumas que den cero en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "0".
  - Las sumas que den dos en la variable "bandera" son coincidencias en dos de los modelos para la etiqueta "1".
  - Obtengo el promedio por fila. Aquellos promedios iguales a 0.6666667 les asigno la etiqueta "1" y aquellos con promedio igual a 0.3333333 les asigno la etiqueta "0". Esto lo hago asumiendo que la mayoría tienen "la razón". Si no está en ninguna de estas opciones mantengo la predicción del modelo xgboost, que fue el segundo mayor puntaje en la competencia. 

```{r}
subm_completa %>% 
  mutate(bandera = svmR + xgb3 + catboost,
         promedio = bandera / 3,
         promedio = as.character(promedio),
         rating = if_else(promedio == "0.333333333333333", true = 0,
                          false = if_else(
                            promedio == "0.666666666666667", true = 1,
                            false = xgb3
                          ))) %>% 
  select(id, rating) ->
  sub_29_ensamble_svmRXGBCatboost
head(sub_29_ensamble_svmRXGBCatboost)
```

- **Exportando predicciones:**

```{r}
write_csv(sub_29_ensamble_svmRXGBCatboost,
          file = "../submission/sub_29_ensamble_svmRXGBCatboostBoosting.csv")
```

# Ensamble XGBoost, SVM y Catboost

- El modelo XGBoost fue ajustado con R. Arrojó mejores resultados que el ajustado con Python.
- La máquina de soporte vectorial tiende a tener buenos resultados para clasificar el "0".
- Catboost entrenado con Python es el de mejores resultados hasta el momento.

```{r}
library(tidyverse)

subm3 <- read_csv("../submission/sub_03_svmR.csv") %>% 
  rename(svmR = rating)

subm9 <- read_csv("../submission/sub_09_xgboost.csv") %>% 
  rename(xgb3 = rating)

subm17 <- read_csv("../submission/sub_17_catboost_boosting.csv") %>% 
  rename(catboost = rating)

```

- **Data con predicciones de todos los modelos:**

```{r}
subm_completa <- inner_join(subm3, subm9, by = "id") %>% 
  inner_join(subm17, by = "id")
head(subm_completa)
```


- **Ensamble:** el resultado de la "bandera" se interpreta de la siguiente manera:
  - Las sumas que den tres en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "1".
  - Las sumas que den cero en la variable "bandera" son coincidencias en los tres modelos para la etiqueta "0".
  - Las sumas que den dos en la variable "bandera" son coincidencias en dos de los modelos para la etiqueta "1".
  - Obtengo el promedio por fila. Aquellos promedios iguales a 0.6666667 les asigno la etiqueta "1" y aquellos con promedio igual a 0.3333333 les asigno la etiqueta "0". Esto lo hago asumiendo que la mayoría tienen "la razón". Si no está en ninguna de estas opciones mantengo la predicción del modelo catboost, que fue el mayor puntaje en la competencia. 

```{r}
subm_completa %>% 
  mutate(bandera = svmR + xgb3 + catboost,
         promedio = bandera / 3,
         promedio = as.character(promedio),
         rating = if_else(promedio == "0.333333333333333", true = 0,
                          false = if_else(
                            promedio == "0.666666666666667", true = 1,
                            false = catboost
                          ))) %>% 
  select(id, rating) ->
  sub_30_ensamble_svmRXGBCatboost
head(sub_30_ensamble_svmRXGBCatboost)
```

- **Exportando predicciones:**

```{r}
write_csv(sub_30_ensamble_svmRXGBCatboost,
          file = "../submission/sub_30_ensamble_svmRXGBCatboostBoosting.csv")
```

# Conclusiones

- La máquina de soporte vectorial proporciona resultado óptimos para el nivel "0".
- El mejor ensamble se da con la máquina de soporte vectorial, XGBoost (F1) y Catboost (Boosting).
- Incorporar Random Forest al ensamble proporciona sesgos que no dan buenos resultados en la competencia.
- XGBoost y Catboost hasta ahora son los algoritmos más eficientes
- Es de vital importancia elegir una métrica que permita optimizar la tasa de falsos negavitos, es decir, que aumente la tasa de verdaderos negativos, ya que a los modelos les cuesta mucho predecir con exactitud la clase "0".
- Los tiempos de procesamiento son mejores en Python con pycaret, sin embargo, el ajuste que se logra para algoritmos como SVM o XGBoost no es adecuado. La mejor alternativa con lo que he explorado hasta el momento, es utilizar los dos lenguajes.
- Catboost impulsado (ensamble boosting) proporcionó muy buenos resultados, no obstante, lo ejecuté con 10 estimadores (valor por defecto de pycaret). Una buena alternativa sería aumentar el espacio de búsqueda para este algoritmo y probar con mayor número de estimadores al realizar Boosting.
- Es necesario probar otras metodologías de ensamble, tales como Stacking o Blending. Además, hasta ahora he hecho el ensamble sólo con las etiquetas, mas no con las probabilidades predichas.